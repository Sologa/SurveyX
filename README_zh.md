<h2 align="center">SurveyX: Academic Survey Automation via Large Language Models</h2>

<p align="center">
  <i>
✨ 欢迎来到SurveyX！一个自动化的学术调查生成引擎，使您能够在短短一个小时内生成高质量的学术综述论文，从而快速了解某一领域！📚
  </i>
  <br>
  <a href="https://arxiv.org/abs/2502.14776">
      <img src="https://img.shields.io/badge/arXiv-Paper-red.svg?logo=arxiv" alt="arxiv paper">
  </a>
  <a href="http://www.surveyx.cn">
    <img src="https://img.shields.io/badge/SurveyX-Web-blue?style=flat" alt="surveyx.cn">
  </a>
  <a href="https://huggingface.co/papers/2502.14776">
    <img src="https://img.shields.io/badge/Huggingface-🤗-yellow?style=flat" alt="huggingface paper">
  </a>
  <a href="https://github.com/IAAR-Shanghai/SurveyX">
    <img src="https://img.shields.io/github/stars/IAAR-Shanghai/SurveyX?style=flat&logo=github&color=yellow" alt="github stars">
  </a>
    <img src="https://img.shields.io/github/last-commit/IAAR-Shanghai/SurveyX?display_timestamp=author&style=flat&color=green" alt="last commit">
  </a>
  <br>
  <a href="https://discord.gg/gyDaySyktW">
    <img src="https://img.shields.io/discord/1346729313134710817?logo=discord&label=Discord&color=5865f1&style=flat" alt="discord channel">
  </a>
  <a href="https://github.com/IAAR-Shanghai/SurveyX/blob/main/assets/user_groups_123.jpg">
    <img src="https://img.shields.io/badge/Wechat-Group-07c160?style=flat&logo=wechat" alt="Wechat Group">
  </a>
</p>

经过一段时间的紧张开发，SurveyX 的第一个用户界面版本现已上线！🎉
我们热情邀请您试用。不要错过！🔥

<div align="center">
  👉 <strong><a href="https://surveyx.cn/">访问 SurveyX</a></strong> 👈
</div>

## 📄如何使用SurveyX？

1. 访问 **[SurveyX](https://www.surveyx.cn)** 🌐
2. 使用您的邮箱注册 📧
3. 提交您的**主题**和**关键词**（主题是您希望生成的主题，关键词用于在线检索）🔍
4. 坐下来放松一下，您的结果正在生成；完成后您将收到邮件通知！📬
5. 我们重视您的反馈，如果您有任何建议，请随时与我们分享您的想法。📝 [问卷星](https://www.wjx.cn/vm/QNAHWs6.aspx)、[Google Forms](https://forms.gle/m1tDKEu4ed7mN3dh7)或[我们的微信群](assets/user_groups_123.jpg)！

## 🤔 什么是SurveyX？

![surveyx_frame](assets/SurveyX.png)

**SurveyX** 是一个先进的学术综述论文自动生成系统，利用大型语言模型（LLMs）生成高质量、领域特定的学术论文综述。🚀

只需提供 **论文标题** 和 **关键词** 进行文献检索，用户就可以请求针对特定主题的综合学术综述论文。

如果您想了解SurveyX的工作原理或想了解更多关于底层技术和方法，请访问我们的 📑[网站](http://www.surveyx.cn) 以了解更多。

## 🛠️ 反馈

我们重视您的反馈！如有任何问题或建议，请随时与我们联系。感谢您的支持！❤️ 立即加入我们的微信天使用户群！🚀 扫描下方二维码，与我们一起塑造未来！💡

<div align="center">
  <img src="assets/user_groups_123.jpg" alt="Wechat Group" width="300" />
</div>

## 📝 已生成的主题

![many_papers](assets/many_papers.png)

### 示例论文

| Title                                                        | Keywords                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|[A Survey of NoSQL Database Systems for Flexible and Scalable Data Management](./examples/Database/A_Survey_of_NoSQL_Database_Systems_for_Flexible_and_Scalable_Data_Management.pdf) | NoSQL, Database Systems, Flexibility, Scalability, Data Management |
|[Vector Databases and Their Role in Modern Data Management and Retrieval A Survey](./examples/Database/Vector_Databases_and_Their_Role_in_Modern_Data_Management_and_Retrieval_A_Survey.pdf) | Vector Databases, Data Management, Data Retrieval, Modern Applications |
|[Graph Databases A Survey on Models, Data Modeling, and Applications](./examples/Database/Graph_Databases_A_Survey_on_Models.pdf) | Graph Databases, Data Modeling |
|[A Survey on Large Language Model Integration with Databases for Enhanced Data Management and Survey Analysis](./examples/Database/A_Survey_on_Large_Language_Model_Integration_with_Databases_for_Enhanced_Data_Management_and_Survey_Analysis.pdf) | Large Language Models, Database Integration, Data Management, Survey Analysis, Enhanced Processing |
|[A Survey of Temporal Databases Real-Time Databases and Data Management Systems](./examples/Database/A_Survey_of_Temporal_Databases_Real.pdf) | Temporal Databases, Real-Time Databases, Data Management |
| [From BERT to GPT-4: A Survey of Architectural Innovations in Pre-trained Language Models](./examples/Computation_and_Language/Transformer.pdf) | Transformer, BERT, GPT-3, self-attention, masked language modeling, cross-lingual transfer, model scaling |
| [Unsupervised Cross-Lingual Word Embedding Alignment: Techniques and Applications](./examples/Computation_and_Language/low.pdf) | low-resource NLP, few-shot learning, data augmentation, unsupervised alignment, synthetic corpora, NLLB, zero-shot transfer |
| [Vision-Language Pre-training: Architectures, Benchmarks, and Emerging Trends](./examples/Computation_and_Language/multimodal.pdf) | multimodal learning, CLIP, Whisper, cross-modal retrieval, modality fusion, video-language models, contrastive learning |
| [Efficient NLP at Scale: A Review of Model Compression Techniques](./examples/Computation_and_Language/model.pdf) | model compression, knowledge distillation, pruning, quantization, TinyBERT, edge computing, latency-accuracy tradeoff |
| [Domain-Specific NLP: Adapting Models for Healthcare, Law, and Finance](./examples/Computation_and_Language/domain.pdf) | domain adaptation, BioBERT, legal NLP, clinical text analysis, privacy-preserving NLP, terminology extraction, few-shot domain transfer |
| [Attention Heads of Large Language Models: A Survey](./examples/Computation_and_Language/attn.pdf) | attention head, attention mechanism, large language model, LLM,transformer architecture, neural networks, natural language processing |
| [Controllable Text Generation for Large Language Models: A Survey](./examples/Computation_and_Language/ctg.pdf) | controlled text generation, text generation, large language model, LLM,natural language processing |
| [A survey on evaluation of large language models](./examples/Computation_and_Language/eval.pdf) | evaluation of large language models,large language models assessment, natural language processing, AI model evaluation |
| [Large language models for generative information extraction: a survey](./examples/Computation_and_Language/infor.pdf) | information extraction, large language models, LLM,natural language processing, generative AI, text mining |
| [Internal consistency and self feedback of LLM](./examples/Computation_and_Language/inter.pdf) | Internal consistency, self feedback, large language model, LLM,natural language processing, model evaluation, AI reliability |
| [Review of Multi Agent Offline Reinforcement Learning](./examples/Computation_and_Language/multi-agent.pdf) | multi agent, offline policy, reinforcement learning,decentralized learning, cooperative agents, policy optimization |
| [Reasoning of large language model: A survey](./examples/Computation_and_Language/reason.pdf) | reasoning of large language models, large language models, LLM,natural language processing, AI reasoning, transformer models |
| [Hierarchy Theorems in Computational Complexity: From Time-Space Tradeoffs to Oracle Separations](examples/Computational_Complexity/P_vs_.pdf) | P vs NP, NP-completeness, polynomial hierarchy, space complexity, oracle separation, Cook-Levin theorem |
| [Classical Simulation of Quantum Circuits: Complexity Barriers and Implications](examples/Computational_Complexity/BQP.pdf) | BQP, quantum supremacy, Shor's algorithm, post-quantum cryptography, QMA, hidden subgroup problem |
| [Kernelization: Theory, Techniques, and Limits](examples/Computational_Complexity/fixed.pdf) | fixed-parameter tractable (FPT), kernelization, treewidth, W-hierarchy, ETH (Exponential Time Hypothesis), parameterized reduction |
| [Optimal Inapproximability Thresholds for Combinatorial Optimization Problems](examples/Computational_Complexity/PCP.pdf) | PCP theorem, approximation ratio, Unique Games Conjecture, APX-hardness, gap-preserving reduction, LP relaxation |
| [Hardness in P: When Polynomial Time is Not Enough](examples/Computational_Complexity/SETH.pdf) | SETH (Strong Exponential Time Hypothesis), 3SUM conjecture, all-pairs shortest paths (APSP), orthogonal vectors problem, fine-grained reduction, dynamic lower bounds |
| [Consistency Models in Distributed Databases: From ACID to NewSQL](examples/Database/CAP.pdf) | CAP theorem, ACID vs BASE, Paxos/Raft, Spanner, NewSQL, sharding, linearizability |
| [Cloud-Native Databases: Architectures, Challenges, and Future Directions](examples/Database/CAP.pdf) | cloud databases, AWS Aurora, Snowflake, storage-compute separation, auto-scaling, pay-per-query, multi-tenancy |
| [Graph Database Systems: Storage Engines and Query Optimization Techniques](examples/Database/graph.pdf) | graph traversal, Neo4j, SPARQL, property graph, subgraph matching, RDF triplestore, Gremlin |
| [Real-Time Aggregation in TSDBs: Techniques for High-Cardinality Data](examples/Database/time.pdf) | time-series data, InfluxDB, Prometheus, downsampling, time windowing, high-cardinality indexing, stream processing |
| [Self-Driving Databases: A Survey of AI-Powered Autonomous Management](examples/Database/auto.pdf) | autonomous databases, learned indexes, query optimization, Oracle AutoML, workload forecasting, anomaly detection |
| [Multi-Model Databases: Integrating Relational, Document, and Graph Paradigms](examples/Database/mmd.pdf) | multi-model database, MongoDB, ArangoDB, JSONB, unified query language, schema flexibility, polystore |
| [Vector Databases for AI: Efficient Similarity Search and Retrieval-Augmented Generation](examples/Networking_and_Internet_Architecture/vector.pdf) | vector database, FAISS, Milvus, ANN search, embedding indexing, RAG (Retrieval-Augmented Generation), HNSW |
| [Software-Defined Networking: Evolution, Challenges, and Future Scalability](examples/Networking_and_Internet_Architecture/open.pdf) | OpenFlow, control plane/data plane separation, NFV orchestration, network slicing, P4 language, OpenDaylight, scalability bottlenecks |
| [Beyond 5G: Architectural Innovations for Terahertz Communication and Network Slicing](examples/Networking_and_Internet_Architecture/network.pdf) | network slicing, MEC (Multi-access Edge Computing), beamforming, mmWave, URLLC (Ultra-Reliable Low-Latency Communication), O-RAN, energy efficiency |
| [IoT Network Protocols: A Comparative Study of LoRaWAN, NB-IoT, and Thread](examples/Networking_and_Internet_Architecture/LPWAN.pdf) | LPWAN, LoRa, ZigBee 3.0, 6LoWPAN, TDMA scheduling, RPL routing, device density management |
| [Edge Caching in Content Delivery Networks: Algorithms and Economic Incentives](examples/Networking_and_Internet_Architecture/CDN.pdf) | CDN, Akamai, cache replacement policies, DASH (Dynamic Adaptive Streaming), QoE optimization, edge server placement, bandwidth cost reduction |
| [A survey on  flow batteries](examples/Other/battery.pdf)    | battery electrolyte formulation                              |
| [Research on battery electrolyte formulation](examples/Other/flow_battery.pdf) | flow batteries  |

## 📃 引用SurveyX

如果这个项目对您的项目/论文有帮助，请引用我们：

```plain text
@misc{liang2025surveyxacademicsurveyautomation,
      title={SurveyX: Academic Survey Automation via Large Language Models}, 
      author={Xun Liang and Jiawei Yang and Yezhaohui Wang and Chen Tang and Zifan Zheng and Shichao Song and Zehao Lin and Yebin Yang and Simin Niu and Hanyu Wang and Bo Tang and Feiyu Xiong and Keming Mao and Zhiyu li},
      year={2025},
      eprint={2502.14776},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.14776}, 
}
```

<hr style="border: 1px solid #ecf0f1;">

## ⚠️ 注意

- 我们的检索引擎可能无法访问许多需要商业许可的论文。如果您的研究主题需要来自非arXiv来源的论文，由于检索范围的限制，生成论文的质量和全面性可能会受到影响。
- 目前我们仅支持生成英语学术综述论文。其他语言的支持仍在开发中，会在不久的将来上线！
- 为了确保所有用户的公平访问，每个用户每天重复（或多次）提交的issue将会被忽略，优先满足多样化用户需求。

## ⚠️ 免责声明

SurveyX使用先进的语言模型协助生成学术论文。然而，请注意生成的内容仅作为研究辅助工具。用户应验证生成论文的准确性，因为SurveyX无法保证完全符合学术标准。

---

## 🧰 离线开源版本（本仓库）使用指引

> 本仓库提供的开源代码支持离线处理流程：使用您本地的参考文献（Markdown 格式）生成综述。若需完整功能（在线检索、多模态图表检索等），请访问网站端。

### 1）环境准备
- Python 3.11+
- 安装依赖：`pip install -r requirements.txt`
- （可选）LaTeX 环境用于编译 PDF（如 `texlive-full`）
- PDF 文本抽取工具（用于 PDF→MD 脚本）：
  - 优先使用 Poppler 的 `pdftotext`（速度与版面更稳定）
    - macOS: `brew install poppler`
    - Ubuntu/Debian: `sudo apt-get update && sudo apt-get install -y poppler-utils`
    - Windows（scoop）: `scoop install poppler`
  - 备选库：PyMuPDF（fitz）
    - `pip install pymupdf`

### 2）将 PDF 批量转为 Markdown（.md）

使用 Docling 转换 PDF 为 Markdown，并将所有 `.md` 放在同一目录。

安装与模型准备（推荐，适配 8GB M1）：
```bash
pip install -U docling docling-tools
docling-tools models download -o "$HOME/.cache/docling/models"
# macOS（可选，建议用于扫描件）
xcode-select --install
pip install -U ocrmac
```

方式 A —— 正式脚本（推荐）：
```bash
bash scripts/docling_pdf_to_md.sh /path/to/pdfs resources/offline_refs/your_topic
```
- macOS（扫描件）启用 Apple OCR：
  ```bash
  DOC_USE_OCRMAC=1 bash scripts/docling_pdf_to_md.sh /path/to/pdfs resources/offline_refs/your_topic
  ```
- 环境开关：`DOCLING_ARTIFACTS_PATH`（模型缓存）、`DOC_IMAGE_MODE`（默认 placeholder）、`DOC_DEVICE`（macOS 默认 mps）、`DOC_THREADS`（2）、`DOC_PAGE_BATCH`（2）

- 注意：Docling 的 `--ocr` 是布林开关，不需要也不应传入 `true`。脚本会自动追加 `--ocr`（若启用 ocrmac 也会加上 `--ocr-engine ocrmac`）。

方式 B —— 使用测试脚本：
```bash
bash tests/run_test_docling_to_md.sh [输入PDF目录] [输出目录]
```
- 默认：从 `resources/offline_refs/pdfs` 读取，输出到 `resources/offline_refs/docling_md_test`
- 使用环境变量 `DOCLING_ARTIFACTS_PATH="$HOME/.cache/docling/models"`

方式 C —— 直接运行 Docling（8GB M1 推荐参数）：
```bash
docling /path/to/pdfs \
  --to md \
  --image-export-mode placeholder \
  --ocr true --ocr-engine ocrmac --ocr-lang en-US \
  --device mps --num-threads 2 --page-batch-size 2 \
  --output resources/offline_refs/your_topic \
  --artifacts-path "$HOME/.cache/docling/models"
```

说明：
- 建议使用 `--image-export-mode placeholder`，避免在 Markdown 中内嵌 base64 图片，减小体积并有利于后续处理。
- 请将所有 `.md` 放在同一个目录，后续作为离线流程的 `--ref_path` 输入。

（可选）校验 Markdown：
```bash
bash scripts/validate_md_refs.sh resources/offline_refs/your_topic
```

### 3）根据清单下载 PDF（included_papers_*.json）

当你已有筛选后的论文清单（如 `resources/included_papers_20250825_balanced.json`），可以批量下载对应 PDF：

```bash
# Python 方式（可加并发/数量上限等参数）
python scripts/download_papers.py \
  --json resources/included_papers_20250825_balanced.json \
  --out-dir datasets/papers \
  --concurrency 6

# Shell 包装器（与上等价）
bash scripts/download_papers.sh \
  resources/included_papers_20250825_balanced.json \
  datasets/papers -- --concurrency 6

# 或使用 run.sh 子指令
./run.sh download resources/included_papers_20250825_balanced.json datasets/papers -- --concurrency 6
```

说明：
- 默认只下载 `is_included: true` 的条目；如需全部下载，添加 `--all`。
- 输出目录默认 `datasets/papers`，清单会写到 `download_manifest.jsonl`；失败 URL 记录在 `download_failures.txt`。
- 文件名采用 `id - title.pdf`，自动处理非法字符。

### 4）环境自动激活（可选）

主要脚本（`run.sh`、`scripts/docling_pdf_to_md.sh`、`scripts/download_papers.sh`）会在检测到未处于 `surveyx` 环境且系统存在 conda 时，尝试 source `$(conda info --base)/etc/profile.d/conda.sh` 并执行 `conda activate surveyx`。如未安装 conda 将自动跳过，不会报错。你也可以手动激活：

```bash
conda activate surveyx
```

### 4）运行离线流程

```bash
python tasks/offline_run.py \
  --title "Your Survey Title" \
  --key_words "kw1, kw2" \
  --ref_path resources/offline_refs/your_topic
```

注意：离线流程要求所有参考文献集中放在单一目录下，且为 `.md` 格式。首行标题与 Abstract 段将提升清洗与抽取质量。
