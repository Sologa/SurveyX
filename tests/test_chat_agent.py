#!/usr/bin/env python3
"""
ğŸ§ª SurveyX ChatAgentæµ‹è¯•è„šæœ¬

æµ‹è¯•ChatAgentä¸LLM APIçš„è¿æ¥å’ŒåŠŸèƒ½

ä½œè€…: SurveyX Team
åˆ›å»ºæ—¶é—´: 2024-01
"""

import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.configs.logger import get_logger
from src.models.LLM.ChatAgent import ChatAgent
from src.configs.config import (
    REMOTE_URL,
    TOKEN,
    DEFAULT_CHATAGENT_MODEL,
    ADVANCED_CHATAGENT_MODEL,
    REASONING_MODELS,
    DEFAULT_REASONING_EFFORT,
)

logger = get_logger("test_chat_agent")

class ChatAgentTester:
    """ChatAgentæµ‹è¯•ç±»"""

    def __init__(self):
        self.agent = None
        self.test_prompts = {
            "simple": "Hello, can you respond with 'Hello from SurveyX!'?",
            "technical": "Explain what reinforcement learning is in one sentence.",
            "chinese": "è¯·ç”¨ä¸­æ–‡è§£é‡Šä»€ä¹ˆæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ã€‚",
            "long": """
            Write a brief summary about the evolution of natural language processing
            from rule-based systems to modern transformer architectures.
            Keep it under 100 words.
            """
        }

    def test_agent_initialization(self):
        """æµ‹è¯•ChatAgentåˆå§‹åŒ–"""
        logger.info("ğŸ”„ æµ‹è¯•ChatAgentåˆå§‹åŒ–...")
        try:
            start_time = time.time()
            self.agent = ChatAgent()
            init_time = time.time() - start_time

            logger.info(f"âœ… ChatAgentåˆå§‹åŒ–æˆåŠŸï¼Œè€—æ—¶: {init_time:.3f}ç§’")
            logger.info(f"ğŸ”— API URL: {REMOTE_URL}")
            logger.info(f"ğŸ¤– é»˜è®¤æ¨¡å‹: {DEFAULT_CHATAGENT_MODEL}")
            logger.info(f"ğŸš€ é«˜çº§æ¨¡å‹: {ADVANCED_CHATAGENT_MODEL}")

            # æ£€æŸ¥tokenæ˜¯å¦è®¾ç½®
            if TOKEN and TOKEN != "your token here":
                logger.info("âœ… API Tokenå·²è®¾ç½®")
            else:
                logger.warning("âš ï¸ API Tokenæœªè®¾ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")

            return True

        except Exception as e:
            logger.error(f"âŒ ChatAgentåˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def test_env_loading(self):
        """æµ‹è¯• .env è¯»å–ä¸ç¯å¢ƒå˜é‡ä¼˜å…ˆçº§"""
        logger.info("ğŸ”„ æµ‹è¯• .env è¯»å–ä¸ä¼˜å…ˆçº§...")
        import importlib
        import sys as _sys
        import tempfile

        # å¤‡ä»½åŸå§‹ç¯å¢ƒå˜é‡
        original_env = {
            "OPENAI_API_KEY": os.environ.get("OPENAI_API_KEY"),
            "OPENAI_REASONING_EFFORT": os.environ.get("OPENAI_REASONING_EFFORT"),
            "SURVEYX_ENV_FILE": os.environ.get("SURVEYX_ENV_FILE"),
        }

        try:
            with tempfile.TemporaryDirectory() as tmpdir:
                env_path = Path(tmpdir) / ".env"
                env_path.write_text(
                    "OPENAI_API_KEY=sk-from-env-file\nOPENAI_REASONING_EFFORT=high\n",
                    encoding="utf-8",
                )

                # æŒ‡å®šæµ‹è¯•ç”¨ .env æ–‡ä»¶ï¼Œå¹¶æ¸…ç©ºç›¸å…³ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿ä»æ–‡ä»¶è¯»å–
                os.environ["SURVEYX_ENV_FILE"] = str(env_path)
                os.environ.pop("OPENAI_API_KEY", None)
                os.environ.pop("OPENAI_REASONING_EFFORT", None)

                # é‡æ–°åŠ è½½é…ç½®æ¨¡å—
                if "src.configs.config" in _sys.modules:
                    del _sys.modules["src.configs.config"]
                config = importlib.import_module("src.configs.config")

                assert config.TOKEN == "sk-from-env-file"
                assert config.DEFAULT_REASONING_EFFORT == "high"

                # ç¯å¢ƒå˜é‡åº”è¦†ç›– .env æ–‡ä»¶
                os.environ["OPENAI_API_KEY"] = "sk-from-env-var"
                os.environ["OPENAI_REASONING_EFFORT"] = "low"
                del _sys.modules["src.configs.config"]
                config = importlib.import_module("src.configs.config")
                assert config.TOKEN == "sk-from-env-var"
                assert config.DEFAULT_REASONING_EFFORT == "low"

            logger.info("âœ… .env è¯»å–ä¸ä¼˜å…ˆçº§æµ‹è¯•é€šè¿‡")
            return True
        except AssertionError as e:
            logger.error(f"âŒ .env è¯»å–æµ‹è¯•æ–­è¨€å¤±è´¥: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ .env è¯»å–æµ‹è¯•å¼‚å¸¸: {e}")
            return False
        finally:
            # æ¢å¤ç¯å¢ƒå˜é‡å¹¶é‡è½½æ¨¡å—ï¼Œé¿å…å½±å“å…¶ä»–æµ‹è¯•
            for k, v in original_env.items():
                if v is None:
                    os.environ.pop(k, None)
                else:
                    os.environ[k] = v
            try:
                if "src.configs.config" in _sys.modules:
                    del _sys.modules["src.configs.config"]
                importlib.import_module("src.configs.config")
            except Exception:
                pass

    def test_simple_api_call(self, model_name):
        """æµ‹è¯•ç®€å•APIè°ƒç”¨"""
        logger.info(f"ğŸ”„ æµ‹è¯•{model_name}æ¨¡å‹APIè°ƒç”¨...")

        try:
            prompt = self.test_prompts["simple"]
            start_time = time.time()

            # è‹¥ä¸ºæ¨ç†æ¨¡å‹ï¼ˆå«å®¶æ—å‰ç¶´ï¼‰ï¼Œå‰‡é™„å¸¶ reasoning_effort ä¸¦èµ° Responses API
            is_reasoning = False
            try:
                is_reasoning = model_name in REASONING_MODELS or any(
                    model_name.startswith(prefix) for prefix in REASONING_MODELS
                )
            except Exception:
                is_reasoning = False

            kwargs = {
                "text_content": prompt,
                "model": model_name,
                "temperature": 0.1,
            }
            if is_reasoning:
                kwargs["reasoning_effort"] = DEFAULT_REASONING_EFFORT or "medium"

            response = self.agent.remote_chat(**kwargs)

            call_time = time.time() - start_time

            logger.info(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: {call_time:.3f}ç§’")
            logger.info(f"ğŸ“ å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

            # æ£€æŸ¥å“åº”æ˜¯å¦åˆç†
            if len(response.strip()) > 10:
                logger.info("âœ… å“åº”å†…å®¹åˆç†")
            else:
                logger.warning("âš ï¸ å“åº”å†…å®¹è¿‡çŸ­")

            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¢„æœŸå†…å®¹
            if "SurveyX" in response or "Hello" in response:
                logger.info("âœ… å“åº”å†…å®¹ç¬¦åˆé¢„æœŸ")
            else:
                logger.info("â„¹ï¸ å“åº”å†…å®¹: " + response[:100] + "...")

            return True

        except Exception as e:
            logger.error(f"âŒ {model_name}æ¨¡å‹APIè°ƒç”¨å¤±è´¥: {e}")
            return False

    def test_multiple_models(self):
        """æµ‹è¯•å¤šä¸ªæ¨¡å‹"""
        models_to_test = [
            DEFAULT_CHATAGENT_MODEL,
            ADVANCED_CHATAGENT_MODEL,
            "gpt-5-nano",  # å‹™å¿…æ¸¬è©¦ gpt-5-nano
        ]
        results = {}

        for model in models_to_test:
            logger.info(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {model}")
            result = self.test_simple_api_call(model)
            results[model] = result

        return results

    def test_token_monitoring(self):
        """æµ‹è¯•tokenç›‘æ§åŠŸèƒ½"""
        logger.info("ğŸ”„ æµ‹è¯•tokenç›‘æ§åŠŸèƒ½...")

        try:
            from src.models.monitor.token_monitor import TokenMonitor

            # åˆ›å»ºtoken monitor
            monitor = TokenMonitor("test_task", "test_operation")

            # è¿›è¡Œä¸€æ¬¡APIè°ƒç”¨
            prompt = "Count to 10."
            response = self.agent.remote_chat(
                text_content=prompt,
                model=DEFAULT_CHATAGENT_MODEL
            )

            logger.info("âœ… Tokenç›‘æ§æµ‹è¯•å®Œæˆ")
            logger.info(f"ğŸ“ å“åº”: {response}")

            return True

        except Exception as e:
            logger.error(f"âŒ Tokenç›‘æ§æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("ğŸ”„ æµ‹è¯•é”™è¯¯å¤„ç†...")

        try:
            # æµ‹è¯•æ— æ•ˆçš„modelåç§°
            invalid_model = "non-existent-model-12345"
            response = self.agent.remote_chat(
                text_content="Test error handling",
                model=invalid_model,
                temperature=0.1
            )

            logger.info("âš ï¸ é”™è¯¯å¤„ç†æµ‹è¯•: æœªæŒ‰é¢„æœŸå¤±è´¥")
            return False

        except Exception as e:
            logger.info(f"âœ… é”™è¯¯å¤„ç†æ­£å¸¸: {type(e).__name__}")
            return True

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ChatAgentå…¨é¢æµ‹è¯•")
        logger.info("=" * 50)

        test_results = []

        # 0. .env è¯»å–æµ‹è¯•
        test_results.append((".envè¯»å–", self.test_env_loading()))

        # 1. åˆå§‹åŒ–æµ‹è¯•
        test_results.append(("åˆå§‹åŒ–", self.test_agent_initialization()))

        if not test_results[-1][1]:
            logger.error("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡åç»­æµ‹è¯•")
            return test_results

        # 2. å¤šæ¨¡å‹æµ‹è¯•
        model_results = self.test_multiple_models()
        for model, result in model_results.items():
            test_results.append((f"{model}è°ƒç”¨", result))

        # 3. Tokenç›‘æ§æµ‹è¯•
        test_results.append(("Tokenç›‘æ§", self.test_token_monitoring()))

        # 4. é”™è¯¯å¤„ç†æµ‹è¯•
        test_results.append(("é”™è¯¯å¤„ç†", self.test_error_handling()))

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        logger.info("=" * 50)
        logger.info("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")

        passed = 0
        total = len(test_results)

        for test_name, result in test_results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            logger.info(f"  {test_name}: {status}")
            if result:
                passed += 1

        logger.info("-" * 30)
        success_rate = passed / total if total > 0 else 0
        logger.info(f"âœ… é€šè¿‡ç‡: {success_rate:.1%}")
        if passed == total:
            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ChatAgentè¿è¡Œæ­£å¸¸")
        else:
            logger.warning(f"âš ï¸ {total - passed}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

        return test_results

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª SurveyX ChatAgentæµ‹è¯•å·¥å…·")
    print("=" * 40)

    # æ£€æŸ¥ç¯å¢ƒ
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    print(f"ğŸ”— API URL: {REMOTE_URL}")
    print(f"ğŸ”‘ TokençŠ¶æ€: {'å·²è®¾ç½®' if TOKEN and TOKEN != 'your token here' else 'æœªè®¾ç½®'}")

    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_path = project_root / "src" / "configs" / "config.py"
    if config_path.exists():
        print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_path}")
    else:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

    print()

    # è¿è¡Œæµ‹è¯•
    tester = ChatAgentTester()
    results = tester.run_all_tests()

    # è¿”å›é€€å‡ºç 
    passed = sum(1 for _, result in results if result)
    total = len(results)
    success_rate = passed / total if total > 0 else 0

    if success_rate == 1.0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‚¨çš„ChatAgenté…ç½®æ­£ç¡®ã€‚")
        return 0
    elif success_rate >= 0.5:
        print(f"\nâš ï¸ å¤§éƒ¨åˆ†æµ‹è¯•é€šè¿‡ ({passed}/{total})ï¼Œä½†æœ‰ä¸€äº›é—®é¢˜éœ€è¦æ£€æŸ¥ã€‚")
        return 1
    else:
        print(f"\nâŒ å¤§å¤šæ•°æµ‹è¯•å¤±è´¥ ({passed}/{total})ï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚")
        return 2

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
